<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 1 Reproducibility of scientific papers | ML Case Studies</title>
  <meta name="description" content="Case studies for reproducibility, imputation, and interpretability" />
  <meta name="generator" content="bookdown 0.18 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 1 Reproducibility of scientific papers | ML Case Studies" />
  <meta property="og:type" content="book" />
  
  <meta property="og:image" content="images/cover.png" />
  <meta property="og:description" content="Case studies for reproducibility, imputation, and interpretability" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 1 Reproducibility of scientific papers | ML Case Studies" />
  
  <meta name="twitter:description" content="Case studies for reproducibility, imputation, and interpretability" />
  <meta name="twitter:image" content="images/cover.png" />



<meta name="date" content="2020-05-06" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="index.html"/>
<link rel="next" href="imputation.html"/>
<script src="libs/header-attrs/header-attrs.js"></script>
<script src="libs/jquery/jquery.min.js"></script>
<link href="libs/gitbook/css/style.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-clipboard.css" rel="stylesheet" />












<link rel="stylesheet" href="css/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./"><h3>ML Case Studies</h3></a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#technical-setup"><i class="fa fa-check"></i>Technical Setup</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="reproducibility.html"><a href="reproducibility.html"><i class="fa fa-check"></i><b>1</b> Reproducibility of scientific papers</a>
<ul>
<li class="chapter" data-level="1.1" data-path="reproducibility.html"><a href="reproducibility.html#title-of-the-article"><i class="fa fa-check"></i><b>1.1</b> Title of the article</a>
<ul>
<li class="chapter" data-level="1.1.1" data-path="reproducibility.html"><a href="reproducibility.html#abstract"><i class="fa fa-check"></i><b>1.1.1</b> Abstract</a></li>
<li class="chapter" data-level="1.1.2" data-path="reproducibility.html"><a href="reproducibility.html#introduction-and-motivation"><i class="fa fa-check"></i><b>1.1.2</b> Introduction and Motivation</a></li>
<li class="chapter" data-level="1.1.3" data-path="reproducibility.html"><a href="reproducibility.html#related-work"><i class="fa fa-check"></i><b>1.1.3</b> Related Work</a></li>
<li class="chapter" data-level="1.1.4" data-path="reproducibility.html"><a href="reproducibility.html#methodology"><i class="fa fa-check"></i><b>1.1.4</b> Methodology</a></li>
<li class="chapter" data-level="1.1.5" data-path="reproducibility.html"><a href="reproducibility.html#results"><i class="fa fa-check"></i><b>1.1.5</b> Results</a></li>
<li class="chapter" data-level="1.1.6" data-path="reproducibility.html"><a href="reproducibility.html#summary-and-conclusions"><i class="fa fa-check"></i><b>1.1.6</b> Summary and conclusions</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="reproducibility.html"><a href="reproducibility.html#how-to-measure-reproducibility-classification-of-problems-with-reproducing-scientific-papers"><i class="fa fa-check"></i><b>1.2</b> How to measure reproducibility? Classification of problems with reproducing scientific papers</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="reproducibility.html"><a href="reproducibility.html#abstract-1"><i class="fa fa-check"></i><b>1.2.1</b> Abstract</a></li>
<li class="chapter" data-level="1.2.2" data-path="reproducibility.html"><a href="reproducibility.html#introduction"><i class="fa fa-check"></i><b>1.2.2</b> Introduction</a></li>
<li class="chapter" data-level="1.2.3" data-path="reproducibility.html"><a href="reproducibility.html#related-work-1"><i class="fa fa-check"></i><b>1.2.3</b> Related Work</a></li>
<li class="chapter" data-level="1.2.4" data-path="reproducibility.html"><a href="reproducibility.html#methodology-1"><i class="fa fa-check"></i><b>1.2.4</b> Methodology</a></li>
<li class="chapter" data-level="1.2.5" data-path="reproducibility.html"><a href="reproducibility.html#results-1"><i class="fa fa-check"></i><b>1.2.5</b> Results</a></li>
<li class="chapter" data-level="1.2.6" data-path="reproducibility.html"><a href="reproducibility.html#summary-and-conclusions-1"><i class="fa fa-check"></i><b>1.2.6</b> Summary and conclusions</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="reproducibility.html"><a href="reproducibility.html#aging-articles.-how-time-affects-reproducibility-of-scientific-papers"><i class="fa fa-check"></i><b>1.3</b> Aging articles. How time affects reproducibility of scientific papers?</a>
<ul>
<li class="chapter" data-level="1.3.1" data-path="reproducibility.html"><a href="reproducibility.html#abstract-2"><i class="fa fa-check"></i><b>1.3.1</b> Abstract</a></li>
<li class="chapter" data-level="1.3.2" data-path="reproducibility.html"><a href="reproducibility.html#introduction-1"><i class="fa fa-check"></i><b>1.3.2</b> Introduction</a></li>
<li class="chapter" data-level="1.3.3" data-path="reproducibility.html"><a href="reproducibility.html#methodology-2"><i class="fa fa-check"></i><b>1.3.3</b> Methodology</a></li>
<li class="chapter" data-level="1.3.4" data-path="reproducibility.html"><a href="reproducibility.html#results-2"><i class="fa fa-check"></i><b>1.3.4</b> Results</a></li>
<li class="chapter" data-level="1.3.5" data-path="reproducibility.html"><a href="reproducibility.html#summary-and-conclusions-2"><i class="fa fa-check"></i><b>1.3.5</b> Summary and conclusions</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="reproducibility.html"><a href="reproducibility.html#ways-to-reproduce-articles-in-terms-of-release-date-and-magazine"><i class="fa fa-check"></i><b>1.4</b> Ways to reproduce articles in terms of release date and magazine</a>
<ul>
<li class="chapter" data-level="1.4.1" data-path="reproducibility.html"><a href="reproducibility.html#abstract-3"><i class="fa fa-check"></i><b>1.4.1</b> Abstract</a></li>
<li class="chapter" data-level="1.4.2" data-path="reproducibility.html"><a href="reproducibility.html#introduction-and-motivation-1"><i class="fa fa-check"></i><b>1.4.2</b> Introduction and Motivation</a></li>
<li class="chapter" data-level="1.4.3" data-path="reproducibility.html"><a href="reproducibility.html#related-work-2"><i class="fa fa-check"></i><b>1.4.3</b> Related Work</a></li>
<li class="chapter" data-level="1.4.4" data-path="reproducibility.html"><a href="reproducibility.html#methodology-3"><i class="fa fa-check"></i><b>1.4.4</b> Methodology</a></li>
<li class="chapter" data-level="1.4.5" data-path="reproducibility.html"><a href="reproducibility.html#results-3"><i class="fa fa-check"></i><b>1.4.5</b> Results</a></li>
<li class="chapter" data-level="1.4.6" data-path="reproducibility.html"><a href="reproducibility.html#summary-and-conclusions-3"><i class="fa fa-check"></i><b>1.4.6</b> Summary and conclusions</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="reproducibility.html"><a href="reproducibility.html#reproducibility-of-outdated-articles-about-up-to-date-r-packages"><i class="fa fa-check"></i><b>1.5</b> Reproducibility of outdated articles about up-to-date R packages</a>
<ul>
<li class="chapter" data-level="1.5.1" data-path="reproducibility.html"><a href="reproducibility.html#abstract-4"><i class="fa fa-check"></i><b>1.5.1</b> Abstract</a></li>
<li class="chapter" data-level="1.5.2" data-path="reproducibility.html"><a href="reproducibility.html#introduction-and-motivation-2"><i class="fa fa-check"></i><b>1.5.2</b> Introduction and Motivation</a></li>
<li class="chapter" data-level="1.5.3" data-path="reproducibility.html"><a href="reproducibility.html#related-work-3"><i class="fa fa-check"></i><b>1.5.3</b> Related Work</a></li>
<li class="chapter" data-level="1.5.4" data-path="reproducibility.html"><a href="reproducibility.html#methodology-4"><i class="fa fa-check"></i><b>1.5.4</b> Methodology</a></li>
<li class="chapter" data-level="1.5.5" data-path="reproducibility.html"><a href="reproducibility.html#results-4"><i class="fa fa-check"></i><b>1.5.5</b> Results</a></li>
<li class="chapter" data-level="1.5.6" data-path="reproducibility.html"><a href="reproducibility.html#summary-and-conclusions-4"><i class="fa fa-check"></i><b>1.5.6</b> Summary and conclusions</a></li>
</ul></li>
<li class="chapter" data-level="1.6" data-path="reproducibility.html"><a href="reproducibility.html#correlation-between-reproducibility-of-components-of-research-papers-and-their-purpose"><i class="fa fa-check"></i><b>1.6</b> Correlation between reproducibility of components of research papers and their purpose</a>
<ul>
<li class="chapter" data-level="1.6.1" data-path="reproducibility.html"><a href="reproducibility.html#abstract-5"><i class="fa fa-check"></i><b>1.6.1</b> Abstract</a></li>
<li class="chapter" data-level="1.6.2" data-path="reproducibility.html"><a href="reproducibility.html#introduction-and-motivation-3"><i class="fa fa-check"></i><b>1.6.2</b> Introduction and Motivation</a></li>
<li class="chapter" data-level="1.6.3" data-path="reproducibility.html"><a href="reproducibility.html#related-work-4"><i class="fa fa-check"></i><b>1.6.3</b> Related Work</a></li>
<li class="chapter" data-level="1.6.4" data-path="reproducibility.html"><a href="reproducibility.html#methodology-5"><i class="fa fa-check"></i><b>1.6.4</b> Methodology</a></li>
<li class="chapter" data-level="1.6.5" data-path="reproducibility.html"><a href="reproducibility.html#results-5"><i class="fa fa-check"></i><b>1.6.5</b> Results</a></li>
<li class="chapter" data-level="1.6.6" data-path="reproducibility.html"><a href="reproducibility.html#summary-and-conclusions-5"><i class="fa fa-check"></i><b>1.6.6</b> Summary and conclusions</a></li>
</ul></li>
<li class="chapter" data-level="1.7" data-path="reproducibility.html"><a href="reproducibility.html#how-active-development-affects-reproducibility"><i class="fa fa-check"></i><b>1.7</b> How active development affects reproducibility</a>
<ul>
<li class="chapter" data-level="1.7.1" data-path="reproducibility.html"><a href="reproducibility.html#abstract-6"><i class="fa fa-check"></i><b>1.7.1</b> Abstract</a></li>
<li class="chapter" data-level="1.7.2" data-path="reproducibility.html"><a href="reproducibility.html#introduction-and-motivation-4"><i class="fa fa-check"></i><b>1.7.2</b> Introduction and Motivation</a></li>
<li class="chapter" data-level="1.7.3" data-path="reproducibility.html"><a href="reproducibility.html#related-work-5"><i class="fa fa-check"></i><b>1.7.3</b> Related Work</a></li>
<li class="chapter" data-level="1.7.4" data-path="reproducibility.html"><a href="reproducibility.html#methodology-6"><i class="fa fa-check"></i><b>1.7.4</b> Methodology</a></li>
<li class="chapter" data-level="1.7.5" data-path="reproducibility.html"><a href="reproducibility.html#results-6"><i class="fa fa-check"></i><b>1.7.5</b> Results</a></li>
<li class="chapter" data-level="1.7.6" data-path="reproducibility.html"><a href="reproducibility.html#summary-and-conclusions-6"><i class="fa fa-check"></i><b>1.7.6</b> Summary and conclusions</a></li>
</ul></li>
<li class="chapter" data-level="1.8" data-path="reproducibility.html"><a href="reproducibility.html#reproducibility-differences-of-articles-published-in-various-journals-and-using-r-or-python-language"><i class="fa fa-check"></i><b>1.8</b> Reproducibility differences of articles published in various journals and using R or Python language</a>
<ul>
<li class="chapter" data-level="1.8.1" data-path="reproducibility.html"><a href="reproducibility.html#abstract-7"><i class="fa fa-check"></i><b>1.8.1</b> Abstract</a></li>
<li class="chapter" data-level="1.8.2" data-path="reproducibility.html"><a href="reproducibility.html#introduction-and-motivation-5"><i class="fa fa-check"></i><b>1.8.2</b> Introduction and Motivation</a></li>
<li class="chapter" data-level="1.8.3" data-path="reproducibility.html"><a href="reproducibility.html#related-work-6"><i class="fa fa-check"></i><b>1.8.3</b> Related Work</a></li>
<li class="chapter" data-level="1.8.4" data-path="reproducibility.html"><a href="reproducibility.html#methodology-7"><i class="fa fa-check"></i><b>1.8.4</b> Methodology</a></li>
<li class="chapter" data-level="1.8.5" data-path="reproducibility.html"><a href="reproducibility.html#results-7"><i class="fa fa-check"></i><b>1.8.5</b> Results</a></li>
<li class="chapter" data-level="1.8.6" data-path="reproducibility.html"><a href="reproducibility.html#summary-and-conclusions-7"><i class="fa fa-check"></i><b>1.8.6</b> Summary and conclusions</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="imputation.html"><a href="imputation.html"><i class="fa fa-check"></i><b>2</b> Imputation</a></li>
<li class="chapter" data-level="3" data-path="interpretability.html"><a href="interpretability.html"><i class="fa fa-check"></i><b>3</b> Interpretability</a>
<ul>
<li class="chapter" data-level="3.1" data-path="interpretability.html"><a href="interpretability.html#building-an-explainable-model-for-ordinal-classification.-meeting-black-box-model-performance-levels."><i class="fa fa-check"></i><b>3.1</b> Building an explainable model for ordinal classification. Meeting black box model performance levels.</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="interpretability.html"><a href="interpretability.html#abstract-8"><i class="fa fa-check"></i><b>3.1.1</b> Abstract</a></li>
<li class="chapter" data-level="3.1.2" data-path="interpretability.html"><a href="interpretability.html#introduction-and-motivation-6"><i class="fa fa-check"></i><b>3.1.2</b> Introduction and Motivation</a></li>
<li class="chapter" data-level="3.1.3" data-path="interpretability.html"><a href="interpretability.html#related-work-7"><i class="fa fa-check"></i><b>3.1.3</b> Related Work</a></li>
<li class="chapter" data-level="3.1.4" data-path="interpretability.html"><a href="interpretability.html#methodology-8"><i class="fa fa-check"></i><b>3.1.4</b> Methodology</a></li>
<li class="chapter" data-level="3.1.5" data-path="interpretability.html"><a href="interpretability.html#results-8"><i class="fa fa-check"></i><b>3.1.5</b> Results</a></li>
<li class="chapter" data-level="3.1.6" data-path="interpretability.html"><a href="interpretability.html#summary-and-conclusions-8"><i class="fa fa-check"></i><b>3.1.6</b> Summary and conclusions</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="interpretability.html"><a href="interpretability.html#predicting-code-defects-using-interpretable-static-measures."><i class="fa fa-check"></i><b>3.2</b> Predicting code defects using interpretable static measures.</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="interpretability.html"><a href="interpretability.html#abstract-9"><i class="fa fa-check"></i><b>3.2.1</b> Abstract</a></li>
<li class="chapter" data-level="3.2.2" data-path="interpretability.html"><a href="interpretability.html#introduction-and-motivation-7"><i class="fa fa-check"></i><b>3.2.2</b> Introduction and Motivation</a></li>
<li class="chapter" data-level="3.2.3" data-path="interpretability.html"><a href="interpretability.html#related-work-8"><i class="fa fa-check"></i><b>3.2.3</b> Related Work</a></li>
<li class="chapter" data-level="3.2.4" data-path="interpretability.html"><a href="interpretability.html#methodology-9"><i class="fa fa-check"></i><b>3.2.4</b> Methodology</a></li>
<li class="chapter" data-level="3.2.5" data-path="interpretability.html"><a href="interpretability.html#results-9"><i class="fa fa-check"></i><b>3.2.5</b> Results</a></li>
<li class="chapter" data-level="3.2.6" data-path="interpretability.html"><a href="interpretability.html#summary-and-conclusions-9"><i class="fa fa-check"></i><b>3.2.6</b> Summary and conclusions</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="interpretability.html"><a href="interpretability.html#using-interpretable-machine-learning-models-in-the-higgs-boson-detection."><i class="fa fa-check"></i><b>3.3</b> Using interpretable Machine Learning models in the Higgs boson detection.</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="interpretability.html"><a href="interpretability.html#abstract-10"><i class="fa fa-check"></i><b>3.3.1</b> Abstract</a></li>
<li class="chapter" data-level="3.3.2" data-path="interpretability.html"><a href="interpretability.html#introduction-and-motivation-8"><i class="fa fa-check"></i><b>3.3.2</b> Introduction and Motivation</a></li>
<li class="chapter" data-level="3.3.3" data-path="interpretability.html"><a href="interpretability.html#related-work-9"><i class="fa fa-check"></i><b>3.3.3</b> Related Work</a></li>
<li class="chapter" data-level="3.3.4" data-path="interpretability.html"><a href="interpretability.html#methodology-10"><i class="fa fa-check"></i><b>3.3.4</b> Methodology</a></li>
<li class="chapter" data-level="3.3.5" data-path="interpretability.html"><a href="interpretability.html#results-10"><i class="fa fa-check"></i><b>3.3.5</b> Results</a></li>
<li class="chapter" data-level="3.3.6" data-path="interpretability.html"><a href="interpretability.html#summary-and-conclusions-10"><i class="fa fa-check"></i><b>3.3.6</b> Summary and conclusions</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="interpretability.html"><a href="interpretability.html#explainable-feature-engineering-and-comparing-with-black-boxes"><i class="fa fa-check"></i><b>3.4</b> Explainable feature engineering and comparing with black boxes</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="interpretability.html"><a href="interpretability.html#abstract-11"><i class="fa fa-check"></i><b>3.4.1</b> Abstract</a></li>
<li class="chapter" data-level="3.4.2" data-path="interpretability.html"><a href="interpretability.html#introduction-and-motivation-9"><i class="fa fa-check"></i><b>3.4.2</b> Introduction and Motivation</a></li>
<li class="chapter" data-level="3.4.3" data-path="interpretability.html"><a href="interpretability.html#related-work-10"><i class="fa fa-check"></i><b>3.4.3</b> Related Work</a></li>
<li class="chapter" data-level="3.4.4" data-path="interpretability.html"><a href="interpretability.html#methodology-11"><i class="fa fa-check"></i><b>3.4.4</b> Methodology</a></li>
<li class="chapter" data-level="3.4.5" data-path="interpretability.html"><a href="interpretability.html#results-11"><i class="fa fa-check"></i><b>3.4.5</b> Results</a></li>
<li class="chapter" data-level="3.4.6" data-path="interpretability.html"><a href="interpretability.html#summary-and-conclusions-11"><i class="fa fa-check"></i><b>3.4.6</b> Summary and conclusions</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="interpretability.html"><a href="interpretability.html#surpassing-black-box-models-performance-on-unbalanced-data-with-an-interpretable-one."><i class="fa fa-check"></i><b>3.5</b> Surpassing black box model’s performance on unbalanced data with an interpretable one.</a>
<ul>
<li class="chapter" data-level="3.5.1" data-path="interpretability.html"><a href="interpretability.html#abstract-12"><i class="fa fa-check"></i><b>3.5.1</b> Abstract</a></li>
<li class="chapter" data-level="3.5.2" data-path="interpretability.html"><a href="interpretability.html#introduction-and-motivation-10"><i class="fa fa-check"></i><b>3.5.2</b> Introduction and Motivation</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="interpretability.html"><a href="interpretability.html#what-affects-the-price-of-a-house-us-census-data-revisited-after-30-years."><i class="fa fa-check"></i><b>3.6</b> What Affects The Price Of A House? US Census Data Revisited After 30 Years.</a>
<ul>
<li class="chapter" data-level="3.6.1" data-path="interpretability.html"><a href="interpretability.html#abstract-13"><i class="fa fa-check"></i><b>3.6.1</b> Abstract</a></li>
<li class="chapter" data-level="3.6.2" data-path="interpretability.html"><a href="interpretability.html#introduction-2"><i class="fa fa-check"></i><b>3.6.2</b> Introduction</a></li>
<li class="chapter" data-level="3.6.3" data-path="interpretability.html"><a href="interpretability.html#data"><i class="fa fa-check"></i><b>3.6.3</b> Data</a></li>
<li class="chapter" data-level="3.6.4" data-path="interpretability.html"><a href="interpretability.html#methodology-12"><i class="fa fa-check"></i><b>3.6.4</b> Methodology</a></li>
<li class="chapter" data-level="3.6.5" data-path="interpretability.html"><a href="interpretability.html#results-12"><i class="fa fa-check"></i><b>3.6.5</b> Results</a></li>
<li class="chapter" data-level="3.6.6" data-path="interpretability.html"><a href="interpretability.html#conclusions"><i class="fa fa-check"></i><b>3.6.6</b> Conclusions</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="acknowledgements.html"><a href="acknowledgements.html"><i class="fa fa-check"></i><b>4</b> Acknowledgements</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://bookdown.org" target="_blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">ML Case Studies</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="reproducibility" class="section level1" number="1">
<h1><span class="header-section-number">Chapter 1</span> Reproducibility of scientific papers</h1>
<p>The analysis of reproducibility of tools-related scientific papers.</p>

<div id="title-of-the-article" class="section level2" number="1.1">
<h2><span class="header-section-number">1.1</span> Title of the article</h2>
<p><em>Authors: Author 1, Author 2, Author 3 (University)</em></p>
<div id="abstract" class="section level3" number="1.1.1">
<h3><span class="header-section-number">1.1.1</span> Abstract</h3>
</div>
<div id="introduction-and-motivation" class="section level3" number="1.1.2">
<h3><span class="header-section-number">1.1.2</span> Introduction and Motivation</h3>
</div>
<div id="related-work" class="section level3" number="1.1.3">
<h3><span class="header-section-number">1.1.3</span> Related Work</h3>
</div>
<div id="methodology" class="section level3" number="1.1.4">
<h3><span class="header-section-number">1.1.4</span> Methodology</h3>
</div>
<div id="results" class="section level3" number="1.1.5">
<h3><span class="header-section-number">1.1.5</span> Results</h3>
</div>
<div id="summary-and-conclusions" class="section level3" number="1.1.6">
<h3><span class="header-section-number">1.1.6</span> Summary and conclusions</h3>

</div>
</div>
<div id="how-to-measure-reproducibility-classification-of-problems-with-reproducing-scientific-papers" class="section level2" number="1.2">
<h2><span class="header-section-number">1.2</span> How to measure reproducibility? Classification of problems with reproducing scientific papers</h2>
<p><em>Authors: Paweł Koźmiński, Anna Urbala, Wojciech Szczypek (Warsaw University of Technology)</em></p>
<div id="abstract-1" class="section level3" number="1.2.1">
<h3><span class="header-section-number">1.2.1</span> Abstract</h3>
</div>
<div id="introduction" class="section level3" number="1.2.2">
<h3><span class="header-section-number">1.2.2</span> Introduction</h3>
<p>The idea of reproducibility of scientific researches is crucial especially in the area of data science. It has become more important along with the development of methods and algorithms used in machine learning as they are more and more complex and complicated. This issue concerns users of all types: students, scientists, developers. Moreover, attaching code used in a paper, helps readers to focus on the real content rather than sophisticated explanations and descriptions included in the article. It is also valuable because the users can use the code as examples of using the package. <br></p>
<p>However problem of the reproducibility is much more complex, because there is no explicit way of measuring it. It means that most of its definitions divide articles into 2 groups - reproducible and irreproducible. Thus, finding an appropriate reproducibility metrics, which would have wider set of values would result in changing the way reproducability is perceived. As a result such a metric would provide much more information for a person who would be interested in reproducing an article.</p>
<div id="definition" class="section level4" number="1.2.2.1">
<h4><span class="header-section-number">1.2.2.1</span> Definition</h4>
<p>Reproducibility as a problem has been addressed by scientists of various fields of studies. The exact definition also differs among areas of studies. For instance, Patrick Vandewall in 2009 suggested a definition of a reproducible research work: “A research work is called reproducible if all information relevant to the work, including, but not limited to, text, data and code, is made available, such that an independent researcher can reproduce the results” <span class="citation">(Vandewalle, Kovacevic, and Vetterli <a href="#ref-vandewalle2009reproducible" role="doc-biblioref">2009</a>)</span>. On the other hand, Association for Computing Machinery divides the problem into three tasks as follows:<br>
* <strong>Repeatability</strong> (Same team, same experimental setup):<br>
The measurement can be obtained with stated precision by the same team using the same measurement procedure, the same measuring system, under the same operating conditions, in the same location on multiple trials. For computational experiments, this means that a researcher can reliably repeat her own computation.</p>
<ul>
<li><p><strong>Replicability</strong> (Different team, same experimental setup):<br>
The measurement can be obtained with stated precision by a different team using the same measurement procedure, the same measuring system, under the same operating conditions, in the same or a different location on multiple trials. For computational experiments, this means that an independent group can obtain the same result using the author’s own artifacts.</p></li>
<li><p><strong>Reproducibility</strong> (Different team, different experimental setup):<br>
The measurement can be obtained with stated precision by a different team, a different measuring system, in a different location on multiple trials. For computational experiments, this means that an independent group can obtain the same result using artifacts which they develop completely independently.
<br></p></li>
</ul>
<p>For the needs of this chapter we will use the Vandewalle’s definition and treat papers as fully reproducible only when they meet the conditions listed there.</p>
<p>((2)Association for Computing Machinery, <a href="https://www.acm.org/publications/policies/artifact-review-badging" class="uri">https://www.acm.org/publications/policies/artifact-review-badging</a>)</p>
</div>
</div>
<div id="related-work-1" class="section level3" number="1.2.3">
<h3><span class="header-section-number">1.2.3</span> Related Work</h3>
<p>Reproducibility is a hot topic. “Open Science in Software Engineering” <span class="citation">(Fernández et al. <a href="#ref-Fernndez2019OpenSI" role="doc-biblioref">2019</a>)</span> describes the essence of <em>open source</em>, <em>open data</em>, <em>open access</em> and other <em>openness</em>. The article mentions that ability to reproduce work is important for the value of research. <em>Open Science</em> has many positive effects: increases access and citation counts, supports cooperation through open repositories. “Reproducibility Guide”(4) contains a lot of informations and tips on how to make research easier to reproduce. The guide also contains the list of tools that can make our research more reproducible (for example version control and automation. And the most important for us: it includes the checklist of questions that help verify the ability to reproduce. Edward Raff emphasizes the word <em>independent</em> in his article(5). <em>Independent reproducibility</em> means that we can obtain similar results independently of the author and his code.</p>
<p>These articles highlight various aspects of reproducibility. We want to verify how the authors care about reproducibility, what are their biggest reproduction issues and what type of problems can we encounter reproducing articles.</p>
<p>((4)<em>Reproducibility in Science. A Guide to enhancing reproducibility in scientific results and writing</em>, <a href="http://ropensci.github.io/reproducibility-guide/" class="uri">http://ropensci.github.io/reproducibility-guide/</a>)</p>
<p>((5)Edward Raff. <em>Quantifying Independently Reproducible Machine Learning</em>, 2020 <a href="https://thegradient.pub/independently-reproducible-machine-learning/" class="uri">https://thegradient.pub/independently-reproducible-machine-learning/</a>)</p>
</div>
<div id="methodology-1" class="section level3" number="1.2.4">
<h3><span class="header-section-number">1.2.4</span> Methodology</h3>
</div>
<div id="results-1" class="section level3" number="1.2.5">
<h3><span class="header-section-number">1.2.5</span> Results</h3>
</div>
<div id="summary-and-conclusions-1" class="section level3" number="1.2.6">
<h3><span class="header-section-number">1.2.6</span> Summary and conclusions</h3>

</div>
</div>
<div id="aging-articles.-how-time-affects-reproducibility-of-scientific-papers" class="section level2" number="1.3">
<h2><span class="header-section-number">1.3</span> Aging articles. How time affects reproducibility of scientific papers?</h2>
<p><em>Authors: Paweł Morgen, Piotr Sieńko, Konrad Welkier (Warsaw University of Technology)</em></p>
<div id="abstract-2" class="section level3" number="1.3.1">
<h3><span class="header-section-number">1.3.1</span> Abstract</h3>
<p>Reproduction of a code presented in scientific papers tend to be a laborious yet important process since it enables readers better understanding of the tools proposed by the authors. While recreating an article various difficulties are faced what can result in calling the paper irreproducible. Some reasons why such situations occur stem from the year when the article was published (for example usage of no more supported packages). The purpose of the following paper is to prove whether this is a general trend which means answering the question: is the year when the article was published related to the reproducibility of the paper. To do so a package CodeExtractorR was created that enables extracting code from PDF files. By using this tool a significant number of articles could be analyzed and therefore results received enabled us to give an objective answer to the stated question.</p>
</div>
<div id="introduction-1" class="section level3" number="1.3.2">
<h3><span class="header-section-number">1.3.2</span> Introduction</h3>
<p>Every article published in scientific journal is aimed at improving our knowledge in certain field. To prove their theories, authors should provide papers with detailed, working examples and extensive supplementary materials to reproduce results. Unfortunately these conditions are not always fulfilled. In a such case, other researchers are not able to verify and accept solutions presented by the author. Moreover, article is not only useless for the scientific community but also for business recipients.</p>
<p>Over the years, several different definitions of reproducibility have been proposed. According to Robert Gentleman and Duncan Temple Lang <span class="citation">(Gentleman and Temple Lang <a href="#ref-gentleman2007statistical" role="doc-biblioref">2007</a>)</span>, reproducible research are papers with accompanying software tools that allow the reader to directly reproduce methods that are presented in the research paper. Other authors suggest that scientific paper is reproducible only if text, data and code are made available and allow independent researcher to recreate the results <span class="citation">(Vandewalle, Kovacevic, and Vetterli <a href="#ref-vandewalle2009reproducible" role="doc-biblioref">2009</a>)</span>. Second definition emphasize importance of accessibility to data used in researches, therefore it seems to be more suitable and complete interpretation of reproducibility. In addition, in this article, we used scale based on the spectrum of reproducibility, proposed by Roger D. Peng <span class="citation">(Peng <a href="#ref-Peng1226" role="doc-biblioref">2011</a>)</span>. In his work, he also mentioned reproducibility as minimal requirement for assessing the scientific value of paper. In the past few years, computing has become essential part of scientific workflow. Some best practices for writing and publishing reproducible scientific article were presented by V. Stodden <span class="citation">(Stodden et al. <a href="#ref-Stodden2013SettingTD" role="doc-biblioref">2013</a>)</span>. Furthermore, she made brief overview of existing tools and software that facilitate this task. Similar issue was closely described by Kitzes <span class="citation">(Kitzes, Turek, and Deniz <a href="#ref-kitzes2017practice" role="doc-biblioref">2017</a>)</span>. Tools created solely for reproducibility in R were proposed by Ben Marwick <span class="citation">(Marwick, <a href="#ref-marwickrrtools" role="doc-biblioref">n.d.</a>)</span> in package rrtools.</p>
<p>Although many articles focus on software or framework solutions for reproducibility problems, analysis of scientific papers reproducibility in the context of release date has, to the best of the authors’ knowledge, not been described before. The intention of such research is to find correlations between age of article and its reproducibility. Authors believe that finding these dependencies will allow to calculate estimated life span of data science article. Furthermore, as replicability helps with applying proposed methods and tools, its approximated level might be helpful in estimating usefulness of every scientific article.</p>
</div>
<div id="methodology-2" class="section level3" number="1.3.3">
<h3><span class="header-section-number">1.3.3</span> Methodology</h3>
</div>
<div id="results-2" class="section level3" number="1.3.4">
<h3><span class="header-section-number">1.3.4</span> Results</h3>
</div>
<div id="summary-and-conclusions-2" class="section level3" number="1.3.5">
<h3><span class="header-section-number">1.3.5</span> Summary and conclusions</h3>

</div>
</div>
<div id="ways-to-reproduce-articles-in-terms-of-release-date-and-magazine" class="section level2" number="1.4">
<h2><span class="header-section-number">1.4</span> Ways to reproduce articles in terms of release date and magazine</h2>
<p><em>Authors: Mikołaj Malec, Maciej Paczóski, Bartosz Rożek</em></p>
<div id="abstract-3" class="section level3" number="1.4.1">
<h3><span class="header-section-number">1.4.1</span> Abstract</h3>
</div>
<div id="introduction-and-motivation-1" class="section level3" number="1.4.2">
<h3><span class="header-section-number">1.4.2</span> Introduction and Motivation</h3>
<p>Reproducibility is a topic which is quite diminished in today’s science world. Scientific articles should be current as long as possible. Their results should be achievable by reader and be the same. Thanks to that science and business world can take advantage of them.The more article is difficult to reproduce, the chance of using knowledge coming from it is smaller. Many researchers tried to define or give principles for reproducibility. There is article published in 2016: “What does research reproducibility mean?” <span class="citation">(Goodman, Fanelli, and Ioannidis <a href="#ref-Goodman2016" role="doc-biblioref">2016</a>)</span> which tried to warn about reproducibility crisis. Article in 2017: “Computational reproducibility in archaeological research: basic principles and a case study of their implementation” <span class="citation">(Marwick <a href="#ref-Marwick2016" role="doc-biblioref">2016</a>)</span>, compered computational reproducibility to archaeological research and give guidelines for researches to use reproducibility in computing research. But these are just two of many articles about reproducibility. Some articles are about tools and techniques for computational reproducibility <span class="citation">(Piccolo and Frampton <a href="#ref-Piccolo2016" role="doc-biblioref">2016</a>)</span>. They encourage researchers to compute data using environments like Jupiter <span class="citation">(Thomas et al. <a href="#ref-Kluyver2016" role="doc-biblioref">2016</a>)</span> or R markdown <span class="citation">(Marwick, Boettiger, and Mullen <a href="#ref-Marwick2017" role="doc-biblioref">2017</a>)</span>. Thanks to that readers can reproduce finding on their own. What’s new about our approach to the subject of reproducibility is focusing on how can release date and magazine affect the amount of work needed to fully reproduce code or is it even possible. A comprehensive comparison of scientific magazines in terms of reproducibility is yet to be created and this article is our best effort to make it happen.
Mikołaj Malec</p>
</div>
<div id="related-work-2" class="section level3" number="1.4.3">
<h3><span class="header-section-number">1.4.3</span> Related Work</h3>
</div>
<div id="methodology-3" class="section level3" number="1.4.4">
<h3><span class="header-section-number">1.4.4</span> Methodology</h3>
</div>
<div id="results-3" class="section level3" number="1.4.5">
<h3><span class="header-section-number">1.4.5</span> Results</h3>
</div>
<div id="summary-and-conclusions-3" class="section level3" number="1.4.6">
<h3><span class="header-section-number">1.4.6</span> Summary and conclusions</h3>

</div>
</div>
<div id="reproducibility-of-outdated-articles-about-up-to-date-r-packages" class="section level2" number="1.5">
<h2><span class="header-section-number">1.5</span> Reproducibility of outdated articles about up-to-date R packages</h2>
<p><em>Authors: Zuzanna Mróz, Aleksander Podsiad, Michał Wdowski (Warsaw University of Technology)</em></p>
<div id="abstract-4" class="section level3" number="1.5.1">
<h3><span class="header-section-number">1.5.1</span> Abstract</h3>
</div>
<div id="introduction-and-motivation-2" class="section level3" number="1.5.2">
<h3><span class="header-section-number">1.5.2</span> Introduction and Motivation</h3>
<p>The problem of the inability to reproduce the results of research presented in a scientific article may result from a number of reasons - at each stage of design, implementation, analysis and description of research results we must remember the problem of reproducibility - without sufficient attention paid to it, there is no chance to ensure the possibility of reproducing the results obtained by one team at a later time and by other people who often do not have full knowledge of the scope presented in the article. Reproducibility is a problem in both business and science. Science, because it allows credibility of research results <span class="citation">(McNutt <a href="#ref-McNutt679" role="doc-biblioref">2014</a>)</span>. Business, because we care about the correct operation of technology in any environment <span class="citation">(Anda, Sjøberg, and Mockus <a href="#ref-Anda407" role="doc-biblioref">2009</a>)</span>.
As cited from “What does research reproducibility mean?” <span class="citation">(Goodman, Fanelli, and Ioannidis <a href="#ref-Goodman2016" role="doc-biblioref">2016</a>)</span>;
“Although the importance of multiple studies corroborating a given result is acknowledged in virtually all of the sciences, the modern use of “reproducible research” was originally applied not to corroboration, but to transparency, with application in the computational sciences. Computer scientist Jon Claerbout coined the term and associated it with a software platform and set of procedures that permit the reader of a paper to see the entire processing trail from the raw data and code to figures and tables. This concept has been carried forward into many data-intensive domains, including epidemiology, computational biology, economics, and clinical trials. According to a U.S. National Science Foundation (NSF) subcommittee on replicability in science, “reproducibility refers to the ability of a researcher to duplicate the results of a prior study using the same materials as were used by the original investigator. That is, a second researcher might use the same raw data to build the same analysis files and implement the same statistical analysis in an attempt to yield the same results…. Reproducibility is a minimum necessary condition for a finding to be believable and informative.”
Other notable articles about reproducibility include “Variability and Reproducibility in Software Engineering: A Study of Four Companies that Developed the Same System” <span class="citation">(Anda, Sjøberg, and Mockus <a href="#ref-Anda407" role="doc-biblioref">2009</a>)</span>, “Reproducible Research in Computational Science” <span class="citation">(Peng <a href="#ref-Peng1226" role="doc-biblioref">2011</a>)</span> and “A statistical definition for reproducibility and replicability” <span class="citation">(Patil, Peng, and Leek <a href="#ref-Patil066803" role="doc-biblioref">2016</a>)</span>.
“Variability and Reproducibility in Software Engineering: A Study of Four Companies that Developed the Same System” focuses on the variability and reproducibility of the outcome of complete software development projects that were carried out by professional developers.
“Reproducible Research in Computational Science” is about limitations in our ability to evaluate published findings and how reproducibility has the potential to serve as a minimum standard for judging scientific claims when full independent replication of a study is not possible.
“A statistical definition for reproducibility and replicability” provides formal and informal definitions of scientific studies, reproducibility, and replicability that can be used to clarify discussions around these concepts in the scientific and popular press.
In our article we focus on the reproduction of old scientific articles on R and packages, which are still being developed. We want to explore how the passage of time affects the ability to reproduce results using the currently available updated tools. We are therefore testing backward compatibility for different packages and checking what affects the reproducibility of the code.
We were unable to find scientific articles on this exact issue. There are articles that give ways to measure reproducibility, as well as articles about packages that help with reproduction. But there are yet no articles that summarize the set of packages in terms of their reproducibility.</p>
</div>
<div id="related-work-3" class="section level3" number="1.5.3">
<h3><span class="header-section-number">1.5.3</span> Related Work</h3>
</div>
<div id="methodology-4" class="section level3" number="1.5.4">
<h3><span class="header-section-number">1.5.4</span> Methodology</h3>
</div>
<div id="results-4" class="section level3" number="1.5.5">
<h3><span class="header-section-number">1.5.5</span> Results</h3>
</div>
<div id="summary-and-conclusions-4" class="section level3" number="1.5.6">
<h3><span class="header-section-number">1.5.6</span> Summary and conclusions</h3>

</div>
</div>
<div id="correlation-between-reproducibility-of-components-of-research-papers-and-their-purpose" class="section level2" number="1.6">
<h2><span class="header-section-number">1.6</span> Correlation between reproducibility of components of research papers and their purpose</h2>
<p><em>Authors: Przemysław Chojecki, Kacper Staroń, Jakub Szypuła (Warsaw University of Technology)</em></p>
<div id="abstract-5" class="section level3" number="1.6.1">
<h3><span class="header-section-number">1.6.1</span> Abstract</h3>
</div>
<div id="introduction-and-motivation-3" class="section level3" number="1.6.2">
<h3><span class="header-section-number">1.6.2</span> Introduction and Motivation</h3>
<p>It is common knowledge that reproducibility is a way for science to evolve. It is the heart of the scientific method to revisit pre-existing measurements and to try to reproduce its results. However, the term „reproducibility” itself, as well it is crucial to the scientific methodology, it can be also universal at the expense of unambiguousness and usability.<br />
For the purpose of this paper we will have recourse to the definition introduced by ACM:<br />
Reproducibility - The measurement can be obtained with stated precision by a different team, a different measuring system, in a different location on multiple trials. For computational experiments, this means that an independent group can obtain the same resultusing artefacts which they develop completely independently.<br />
This particular definition ilustrates perfectly how in the course of establishing the meaning of term „Reproducibility”, the level of importance of auxiliary measurements and settings of the experiment to the overall results is omitted. It is notably significant misconception especially in the experiments from the field of computional science, when reproducing or even maintaining precise operating conditions is usually impossible.<br />
In the following chapters we will attempt to perform an analysis of reproducibility of the papers submitted to the RJournal, regarding especially presumed objectives of enclosed auxilliary computations and artifacts (i. e. code chunks) in overarching structure of a given paper.<br />
</p>
</div>
<div id="related-work-4" class="section level3" number="1.6.3">
<h3><span class="header-section-number">1.6.3</span> Related Work</h3>
<p>Although there are many research papers related to this article, the following three could be perceived as a “basis” for our study.<br />
1. <a href="https://arxiv.org/pdf/1904.06499.pdf">Daniel Mendez, Daniel Graziotin, Stefan Wagner, and Heidi Seibold, 2019</a> provides a definition of reproducibility this article uses, and distinguishes it from replicability.<br />
2. <a href="https://stm.sciencemag.org/content/8/341/341ps12">Steven N. Goodman*, Daniele Fanelli and John P. A. Ioannidis, 2016</a> defines multiple interpretations of reproducibility. It further divides and classifies reproducibility, and provides a basis on how one can do it.<br />
3. <a href="https://www.pnas.org/content/pnas/115/11/2584.full.pdf">Victoria Stodden, Jennifer Seiler, and Zhaokun Mab, 2018</a> is an example of how one conducts a study on reproducibility within articles of a specific journal. It also provides a frame of reference to compare results.<br />
</p>
<p>In their search the authors have not encountered other research papers that study the aspect of reproducibility this article focuses on. If said papers do not actually exist, then this article could provide insights on previously unexamined aspects of reproducibility.<br />
</p>
</div>
<div id="methodology-5" class="section level3" number="1.6.4">
<h3><span class="header-section-number">1.6.4</span> Methodology</h3>
</div>
<div id="results-5" class="section level3" number="1.6.5">
<h3><span class="header-section-number">1.6.5</span> Results</h3>
</div>
<div id="summary-and-conclusions-5" class="section level3" number="1.6.6">
<h3><span class="header-section-number">1.6.6</span> Summary and conclusions</h3>

</div>
</div>
<div id="how-active-development-affects-reproducibility" class="section level2" number="1.7">
<h2><span class="header-section-number">1.7</span> How active development affects reproducibility</h2>
<p><em>Authors: Ngoc Anh Nguyen, Piotr Piątyszek, Marcin Łukaszyk (Warsaw University of Technology)</em></p>
<div id="abstract-6" class="section level3" number="1.7.1">
<h3><span class="header-section-number">1.7.1</span> Abstract</h3>
</div>
<div id="introduction-and-motivation-4" class="section level3" number="1.7.2">
<h3><span class="header-section-number">1.7.2</span> Introduction and Motivation</h3>
<p>The key quality in measuring the outcome of researches and experiments is whether results in a paper can be attained by a different research team, using the same methods. Results presented in scientific articles may sometimes seem revolutionary, but there is very little use if it was just a single case impossible to reproduce. The closeness of agreement among repeated measurements of a variable made under the same operating conditions by different people, or over a period of time is what researches must bear in mind. Professor Roger D. Peng, leading author of the commentary and an advocate for making research reproducible by others, insists reproducibility should be a minimal standard <span class="citation">(Peng <a href="#ref-Peng1226" role="doc-biblioref">2011</a>)</span>.</p>
<p>There have been several reproducibility definitions proposed during the last decades. Gentleman and Temple Lang <span class="citation">(Gentleman and Temple Lang <a href="#ref-gentleman2007statistical" role="doc-biblioref">2007</a>)</span> suggest that by reproducible research, we mean research papers with accompanying software tools that allow the reader to directly reproduce the results and employ the computational methods that are presented in the research paper. The second definition is according to Vandewalle et al. <span class="citation">(Vandewalle, Kovacevic, and Vetterli <a href="#ref-vandewalle2009reproducible" role="doc-biblioref">2009</a>)</span>, research work is called reproducible if all information relevant to the work, including, but not limited to, text, data, and code, is made available, such that an independent researcher can reproduce the results. As said by LeVeque <span class="citation">(LeVeque <a href="#ref-leveque2009python" role="doc-biblioref">2009</a>)</span> the idea of ‘reproducible research’ in scientific computing is to archive and make publicly available all the codes used to create a paper’s figures or tables, preferably in such a manner that readers can download the codes and run them to reproduce the results. All definitions converge into one consistent postulate - the data and code should be made available for others to view and use. The availability of all information related to research paper gives other investigators the opportunity to verify previously published findings, conduct alternative analyses of the same data, eliminate uninformed criticisms and most importantly - expedite the exchange of information among scientists.</p>
<p>Reproducibility has great importance not only in the academic world but also it also plays a significant role in the business. The concept of technological dept is often used to describe the implied cost of additional rework caused by choosing an easy solution now instead of using a better approach that would take longer in software development.</p>
<p>There are papers about using version control systems to provide reproducible results <span class="citation">(Stanisic, Legrand, and Danjean <a href="#ref-stanisic2015an" role="doc-biblioref">2015</a>)</span>. The authors presented how we can manage to maintain our goal of reproducibility using Git and Org-Mode. Other researchers have created a software package that is designed to create reproducible data analysis <span class="citation">(Fomel et al. <a href="#ref-fomel2013madagascar" role="doc-biblioref">2013</a>)</span>. They have created a package that contains computational modules, data processing scripts, and research papers. The package is build using the Unix principle to write programs that are simple and do well one thing. The program breaks big data analysis chains into small steps to ensure that everything is going in the right way. Some papers suggest using Docker to make sure our research can be reproduced <span class="citation">(Hung et al. <a href="#ref-hung2016guidock" role="doc-biblioref">2016</a>)</span>.</p>
<p>The main goal of our work is to measure the impact of the active development of packages on the reproducibility of scientific papers. Multiple authors <span class="citation">(Rosenberg et al. <a href="#ref-rosenberg2020the" role="doc-biblioref">2020</a>; Kitzes, Turek, and Deniz <a href="#ref-kitzes2017practice" role="doc-biblioref">2017</a>)</span> suggest using the version control system as a key feature in creating reproducible research. The second paper also provides evidence, that this is widely known. Git and GitHub were used in over 80% of cases. However, there are two kinds of using a version control system. An author can push software into the repository, to make it easily accessible and does not update it anymore. The second option is to keep the repository up-to-date and resolve users’ issues. We have not found any research on how these two approaches impact reproducibility.</p>
</div>
<div id="related-work-5" class="section level3" number="1.7.3">
<h3><span class="header-section-number">1.7.3</span> Related Work</h3>
</div>
<div id="methodology-6" class="section level3" number="1.7.4">
<h3><span class="header-section-number">1.7.4</span> Methodology</h3>
</div>
<div id="results-6" class="section level3" number="1.7.5">
<h3><span class="header-section-number">1.7.5</span> Results</h3>
</div>
<div id="summary-and-conclusions-6" class="section level3" number="1.7.6">
<h3><span class="header-section-number">1.7.6</span> Summary and conclusions</h3>

</div>
</div>
<div id="reproducibility-differences-of-articles-published-in-various-journals-and-using-r-or-python-language" class="section level2" number="1.8">
<h2><span class="header-section-number">1.8</span> Reproducibility differences of articles published in various journals and using R or Python language</h2>
<p><em>Authors: Bartłomiej Eljasiak, Konrad Komisarczyk, Mariusz Słapek (Warsaw University of Technology)</em></p>
<div id="abstract-7" class="section level3" number="1.8.1">
<h3><span class="header-section-number">1.8.1</span> Abstract</h3>
</div>
<div id="introduction-and-motivation-5" class="section level3" number="1.8.2">
<h3><span class="header-section-number">1.8.2</span> Introduction and Motivation</h3>
<p>Due to the growing number of research publications and open-source solutions, the importance of repeatability and reproducibility is increasing. Although reproducibility is a cornerstone of science, a large amount of published research results cannot be reproduced <span class="citation">(Gundersen and Kjensmo <a href="#ref-AAAI1817248" role="doc-biblioref">2018</a>)</span>. Repeatability and reproducibility are closely related to science.</p>
<p>“Reproducibility of a method/test can be defined as the closeness of the agreement between independent results obtained with the same method on the identical subject(s) (or object, or test material) but under different conditions (different observers, laboratories etc.). (…) On the other hand, repeatability denotes the closeness of the agreement between independent results obtained with the same method on the identical subject(s) (or object or test material), under the same conditions.”<span class="citation">(Slezak and Waczulikova <a href="#ref-SlezakWaczulikova2011" role="doc-biblioref">2011</a>)</span></p>
<p>Reproducibility is crucial since it is what an researcher can guarantee about a research. This not only ensures that the results are correct, but rather ensures transparency and gives scientists confidence in understanding exactly what was done <span class="citation">(Eisner <a href="#ref-Eisner2018" role="doc-biblioref">2018</a>)</span>. It allows science to progress by building on previous work. What is more, it is necessary to prevent scientific misconduct. The increasing number of cases is causing a crisis of confidence in science <span class="citation">(Drummond <a href="#ref-Drummond2012" role="doc-biblioref">2012</a>)</span>.</p>
<p>In psychology the problem has already been addressed. From 2011 to 2015 over two hundred scientists cooperated to reproduce results of one hundred psychological studies <span class="citation">(Anderson et al. <a href="#ref-Ezcuj" role="doc-biblioref">2019</a>)</span>. In computer science (and data science) scientists notice the need for creating tools and guidelines, which help to guarantee reproducibility of solutions <span class="citation">(Biecek and Kosinski <a href="#ref-Archivist" role="doc-biblioref">2017</a>, @Stodden1240)</span>. There exist already developed solutions which are tested to be applied <span class="citation">(Elmenreich et al. <a href="#ref-Elmenreich2018" role="doc-biblioref">2018</a>)</span>.</p>
<p>Reproducibility can focus on different aspects of the publication, including code, results of analysis and data collection methods. This work will focus mainly on the code - results produced by evaluation of different functions and chunks of code from analysed publications.</p>
<p>In this paper we want to compare journals on the reproducibility of their articles. Moreover, we will present the reproducibility differences between R and Python - two of the most popular programming languages in data science publications.There is discussion between proponents of these two languages, which one is more convenient to use in data science. Different journals also compete between each other. There are already many metrics devised to assess which journal is better regarding this metric <span class="citation">(Elsevier, <a href="#ref-JournalMetrics" role="doc-biblioref">n.d.</a>)</span>.
There are no publications related to the reproducibility topic which compare different journals and languages. Although there are some exploring reproducibility within one specific journal <span class="citation">(Stodden, Seiler, and Ma <a href="#ref-Stodden2584" role="doc-biblioref">2018</a>)</span>. What is more, journals notice the importance of this subject <span class="citation">(McNutt <a href="#ref-McNutt679" role="doc-biblioref">2014</a>)</span>. Also according to scientists journals should take some responsibility for this subject <span class="citation">(Eisner <a href="#ref-Eisner2018" role="doc-biblioref">2018</a>)</span>.</p>
</div>
<div id="related-work-6" class="section level3" number="1.8.3">
<h3><span class="header-section-number">1.8.3</span> Related Work</h3>
</div>
<div id="methodology-7" class="section level3" number="1.8.4">
<h3><span class="header-section-number">1.8.4</span> Methodology</h3>
</div>
<div id="results-7" class="section level3" number="1.8.5">
<h3><span class="header-section-number">1.8.5</span> Results</h3>
</div>
<div id="summary-and-conclusions-7" class="section level3" number="1.8.6">
<h3><span class="header-section-number">1.8.6</span> Summary and conclusions</h3>

</div>
</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-Anda407">
<p>Anda, Bente, Dag Sjøberg, and Audris Mockus. 2009. “Variability and Reproducibility in Software Engineering: A Study of Four Companies That Developed the Same System.” <em>Software Engineering, IEEE Transactions on</em> 35 (July): 407–29. <a href="https://doi.org/10.1109/TSE.2008.89">https://doi.org/10.1109/TSE.2008.89</a>.</p>
</div>
<div id="ref-Ezcuj">
<p>Anderson, Christopher, Joanna Anderson, Marcel van Assen, Peter Attridge, Angela Attwood, Jordan Axt, Molly Babel, et al. 2019. “Reproducibility Project: Psychology.” <a href="https://doi.org/10.17605/OSF.IO/EZCUJ">https://doi.org/10.17605/OSF.IO/EZCUJ</a>.</p>
</div>
<div id="ref-Archivist">
<p>Biecek, Przemyslaw, and Marcin Kosinski. 2017. “archivist: An R Package for Managing, Recording and Restoring Data Analysis Results.” <em>Journal of Statistical Software</em> 82 (11): 1–28. <a href="https://doi.org/10.18637/jss.v082.i11">https://doi.org/10.18637/jss.v082.i11</a>.</p>
</div>
<div id="ref-Drummond2012">
<p>Drummond, Chris. 2012. “Reproducible Research: A Dissenting Opinion.” In.</p>
</div>
<div id="ref-Eisner2018">
<p>Eisner, D. A. 2018. “Reproducibility of Science: Fraud, Impact Factors and Carelessness.” <em>Journal of Molecular and Cellular Cardiology</em> 114 (January): 364–68. <a href="https://doi.org/10.1016/j.yjmcc.2017.10.009">https://doi.org/10.1016/j.yjmcc.2017.10.009</a>.</p>
</div>
<div id="ref-Elmenreich2018">
<p>Elmenreich, Wilfried, Philipp Moll, Sebastian Theuermann, and Mathias Lux. 2018. “Making Computer Science Results Reproducible - a Case Study Using Gradle and Docker,” August. <a href="https://doi.org/10.7287/peerj.preprints.27082v1">https://doi.org/10.7287/peerj.preprints.27082v1</a>.</p>
</div>
<div id="ref-JournalMetrics">
<p>Elsevier. n.d. “Journal Metrics - Impact, Speed and Reach.”</p>
</div>
<div id="ref-Fernndez2019OpenSI">
<p>Fernández, Daniel Méndez, Daniel Graziotin, Stefan Wagner, and Heidi Seibold. 2019. “Open Science in Software Engineering.” <em>ArXiv</em> abs/1904.06499.</p>
</div>
<div id="ref-fomel2013madagascar">
<p>Fomel, Sergey, Paul Sava, Ioan Vlad, Yang Liu, and Vladimir Bashkardin. 2013. “Madagascar: Open-Source Software Project for Multidimensional Data Analysis and Reproducible Computational Experiments.” <em>Journal of Open Research Software</em> 1 (November): e8. <a href="https://doi.org/10.5334/jors.ag">https://doi.org/10.5334/jors.ag</a>.</p>
</div>
<div id="ref-gentleman2007statistical">
<p>Gentleman, Robert, and Duncan Temple Lang. 2007. “Statistical Analyses and Reproducible Research.” <em>Journal of Computational and Graphical Statistics</em> 16 (1): 1–23.</p>
</div>
<div id="ref-Goodman2016">
<p>Goodman, Steven N., Daniele Fanelli, and John P. A. Ioannidis. 2016. “What Does Research Reproducibility Mean?” <em>Science Translational Medicine</em> 8 (341): 341ps12–341ps12. <a href="https://doi.org/10.1126/scitranslmed.aaf5027">https://doi.org/10.1126/scitranslmed.aaf5027</a>.</p>
</div>
<div id="ref-AAAI1817248">
<p>Gundersen, Odd Erik, and Sigbjørn Kjensmo. 2018. “State of the Art: Reproducibility in Artificial Intelligence.” <a href="https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/17248">https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/17248</a>.</p>
</div>
<div id="ref-hung2016guidock">
<p>Hung, Ling-Hong, Daniel Kristiyanto, Sung Lee, and Ka Yee Yeung. 2016. “GUIdock: Using Docker Containers with a Common Graphics User Interface to Address the Reproducibility of Research.” <em>PloS One</em> 11 (April): e0152686. <a href="https://doi.org/10.1371/journal.pone.0152686">https://doi.org/10.1371/journal.pone.0152686</a>.</p>
</div>
<div id="ref-kitzes2017practice">
<p>Kitzes, Justin, Daniel Turek, and Fatma Deniz. 2017. <em>The Practice of Reproducible Research: Case Studies and Lessons from the Data-Intensive Sciences</em>. Univ of California Press.</p>
</div>
<div id="ref-leveque2009python">
<p>LeVeque, Randall. 2009. “Python Tools for Reproducible Research on Hyperbolic Problems.” <em>Computing in Science &amp; Engineering</em> 11 (January): 19–27. <a href="https://doi.org/10.1109/MCSE.2009.13">https://doi.org/10.1109/MCSE.2009.13</a>.</p>
</div>
<div id="ref-marwickrrtools">
<p>Marwick, B. n.d. “Rrtools: Creates a Reproducible Research Compendium (2018).”</p>
</div>
<div id="ref-Marwick2016">
<p>Marwick, Ben. 2016. “Computational Reproducibility in Archaeological Research: Basic Principles and a Case Study of Their Implementation.” <em>Journal of Archaeological Method and Theory</em> 24 (2): 424–50. <a href="https://doi.org/10.1007/s10816-015-9272-9">https://doi.org/10.1007/s10816-015-9272-9</a>.</p>
</div>
<div id="ref-Marwick2017">
<p>Marwick, Ben, Carl Boettiger, and Lincoln Mullen. 2017. “Packaging Data Analytical Work Reproducibly Using R (and Friends).” <em>The American Statistician</em> 72 (1): 80–88. <a href="https://doi.org/10.1080/00031305.2017.1375986">https://doi.org/10.1080/00031305.2017.1375986</a>.</p>
</div>
<div id="ref-McNutt679">
<p>McNutt, Marcia. 2014. “Journals Unite for Reproducibility.” <em>Science</em> 346 (6210): 679–79. <a href="https://doi.org/10.1126/science.aaa1724">https://doi.org/10.1126/science.aaa1724</a>.</p>
</div>
<div id="ref-Patil066803">
<p>Patil, Prasad, Roger D. Peng, and Jeffrey T. Leek. 2016. “A Statistical Definition for Reproducibility and Replicability.” <em>Science</em>. <a href="https://doi.org/10.1101/066803">https://doi.org/10.1101/066803</a>.</p>
</div>
<div id="ref-Peng1226">
<p>Peng, Roger D. 2011. “Reproducible Research in Computational Science.” <em>Science</em> 334 (6060): 1226–7. <a href="https://doi.org/10.1126/science.1213847">https://doi.org/10.1126/science.1213847</a>.</p>
</div>
<div id="ref-Piccolo2016">
<p>Piccolo, Stephen R., and Michael B. Frampton. 2016. “Tools and Techniques for Computational Reproducibility.” <em>GigaScience</em> 5 (1). <a href="https://doi.org/10.1186/s13742-016-0135-4">https://doi.org/10.1186/s13742-016-0135-4</a>.</p>
</div>
<div id="ref-rosenberg2020the">
<p>Rosenberg, David E., Yves Filion, Rebecca Teasley, Samuel Sandoval-Solis, Jory S. Hecht, Jakobus E. van Zyl, George F. McMahon, Jeffery S. Horsburgh, Joseph R. Kasprzyk, and David G. Tarboton. 2020. “The Next Frontier: Making Research More Reproducible.” <em>Journal of Water Resources Planning and Management</em> 146 (6): 01820002. <a href="https://doi.org/10.1061/(ASCE)WR.1943-5452.0001215">https://doi.org/10.1061/(ASCE)WR.1943-5452.0001215</a>.</p>
</div>
<div id="ref-SlezakWaczulikova2011">
<p>Slezak, Peter, and Iveta Waczulikova. 2011. “Reproducibility and Repeatability.” <em>Physiological Research / Academia Scientiarum Bohemoslovaca</em> 60 (April): 203–4; author reply 204.</p>
</div>
<div id="ref-stanisic2015an">
<p>Stanisic, Luka, Arnaud Legrand, and Vincent Danjean. 2015. “An Effective Git and Org-Mode Based Workflow for Reproducible Research.” <em>SIGOPS Oper. Syst. Rev.</em> 49 (1): 61–70. <a href="https://doi.org/10.1145/2723872.2723881">https://doi.org/10.1145/2723872.2723881</a>.</p>
</div>
<div id="ref-Stodden2013SettingTD">
<p>Stodden, Victoria, David H. Bailey, Jonathan M. Borwein, Randall J. LeVeque, William J. Rider, and William Stein. 2013. “Setting the Default to Reproducible Reproducibility in Computational and Experimental Mathematics.” In.</p>
</div>
<div id="ref-Stodden2584">
<p>Stodden, Victoria, Jennifer Seiler, and Zhaokun Ma. 2018. “An Empirical Analysis of Journal Policy Effectiveness for Computational Reproducibility.” <em>Proceedings of the National Academy of Sciences</em> 115 (11): 2584–9. <a href="https://doi.org/10.1073/pnas.1708290115">https://doi.org/10.1073/pnas.1708290115</a>.</p>
</div>
<div id="ref-Kluyver2016">
<p>Thomas, Kluyver, Ragan-Kelley Benjamin, P&amp;eacute;rez Fernando, Granger Brian, Bussonnier Matthias, Frederic Jonathan, Kelley Kyle, et al. 2016. “Jupyter Notebooks &amp;Ndash; a Publishing Format for Reproducible Computational Workflows.” <em>Stand Alone</em> 0 (Positioning and Power in Academic Publishing: Players, Agents and Agendas): 87–90. <a href="https://doi.org/10.3233/978-1-61499-649-1-87">https://doi.org/10.3233/978-1-61499-649-1-87</a>.</p>
</div>
<div id="ref-vandewalle2009reproducible">
<p>Vandewalle, Patrick, Jelena Kovacevic, and Martin Vetterli. 2009. “Reproducible Research in Signal Processing.” <em>IEEE Signal Processing Magazine</em> 26 (3): 37–47.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="index.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="imputation.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook/js/app.min.js"></script>
<script src="libs/gitbook/js/lunr.js"></script>
<script src="libs/gitbook/js/clipboard.min.js"></script>
<script src="libs/gitbook/js/plugin-search.js"></script>
<script src="libs/gitbook/js/plugin-sharing.js"></script>
<script src="libs/gitbook/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook/js/plugin-bookdown.js"></script>
<script src="libs/gitbook/js/jquery.highlight.js"></script>
<script src="libs/gitbook/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/mini-pw/2020L-WB-Book/edit/master/1-0-reproducibility.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["book.pdf", "book.epub"],
"toc": {
"collapse": "section"
}
});
});
</script>

</body>

</html>
